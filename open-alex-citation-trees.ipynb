{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cce9ecc6-c0ec-4e0d-9a9c-ffe7752ea335",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyvis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnetworkx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnx\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyvis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnetwork\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Network\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display, HTML\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyvis'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import urllib.parse\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import json\n",
    "from IPython.display import display, JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f08045e-f147-473c-a168-e941e39dd524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get work data from OpenAlex API\n",
    "def get_openalex_data(work_id_or_doi):\n",
    "    if work_id_or_doi.startswith('https://'):\n",
    "        url = work_id_or_doi\n",
    "    else:\n",
    "        encoded_doi = urllib.parse.quote(work_id_or_doi)\n",
    "        url = f'https://api.openalex.org/works/https://doi.org/{encoded_doi}'\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f'Error: {response.status_code}')\n",
    "        print(response.text)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2277ce-add5-44d0-91ee-71613da79012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get citing works from OpenAlex API\n",
    "def get_cited_by_data(cited_by_api_url):\n",
    "    response = requests.get(cited_by_api_url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f'Error fetching cited_by_api_url: {response.status_code}')\n",
    "        print(response.text)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28370199-882c-4702-ae9c-de10d203098e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build the citation graph and assign concepts\n",
    "def build_citation_graph(work_data, graph=None, depth=0, max_depth=2):\n",
    "    if graph is None:\n",
    "        graph = nx.DiGraph()\n",
    "    work_id = work_data['id']\n",
    "    \n",
    "    # Extract the primary concept (concept)\n",
    "    #primary_concept = work_data.get('concepts', [{}])[0].get('display_name', 'Unknown concept')\n",
    "    #primary_topic = work_data.get('primary_topic', [{}])[0].get('display_name', 'Unknown domain')\n",
    "    #field = work_data.get('primary_topic', [{}])[1].get('display_name', 'Unknown domain')\n",
    "    #domain = work_data.get('primary_topic', [{}])[2].get('display_name', 'Unknown domain')\n",
    "    #print(domain)\n",
    "\n",
    "    concepts = work_data.get('concepts', [])\n",
    "    primary_concept = concepts[0].get('display_name', 'Unknown concept')\n",
    "    \n",
    "    primary_topic = work_data.get('primary_topic', {}) or {}\n",
    "    #display(JSON(primary_topic))\n",
    "    subfield = (primary_topic.get('subfield') or {}).get('display_name', 'Unknown subfield')\n",
    "    field = (primary_topic.get('field') or {}).get('display_name', 'Unknown field')\n",
    "    #print(field)\n",
    "    \n",
    "    # Add or update the node without passing additional attributes directly in add_node\n",
    "    if work_id not in graph:\n",
    "        graph.add_node(work_id)  # Add node without extra attributes\n",
    "    \n",
    "    # Update depth and concept attributes after adding the node\n",
    "    graph.nodes[work_id]['depth'] = min(depth, graph.nodes[work_id].get('depth', float('inf')))\n",
    "    graph.nodes[work_id]['primary_concept'] = primary_concept\n",
    "    graph.nodes[work_id]['subfield'] = subfield\n",
    "    graph.nodes[work_id]['field'] = field\n",
    "    graph.nodes[work_id].update(work_data)  # Update with other data from work_data\n",
    "    \n",
    "    if depth >= max_depth:\n",
    "        return graph\n",
    "    \n",
    "    cited_by_api_url = work_data.get('cited_by_api_url')\n",
    "    if cited_by_api_url:\n",
    "        citing_works_data = get_cited_by_data(cited_by_api_url)\n",
    "        if citing_works_data:\n",
    "            for citing_work_data in citing_works_data.get('results', []):\n",
    "                citing_work_id = citing_work_data['id']\n",
    "                \n",
    "                # Retrieve primary concept for each citing work\n",
    "                citing_concept = citing_work_data.get('concepts', [{}])[0].get('display_name', 'Unknown concept')\n",
    "\n",
    "                # Add the citing node without extra attributes directly in add_node\n",
    "                if citing_work_id not in graph:\n",
    "                    graph.add_node(citing_work_id)\n",
    "                \n",
    "                # Update depth and concept attributes after adding the node\n",
    "                graph.nodes[citing_work_id]['depth'] = min(depth + 1, graph.nodes[citing_work_id].get('depth', float('inf')))\n",
    "                graph.nodes[citing_work_id]['concept'] = citing_concept  # Set concept\n",
    "                graph.nodes[citing_work_id].update(citing_work_data)  # Update with other data from citing_work_data\n",
    "                \n",
    "                # Add the edge from citer to cited\n",
    "                graph.add_edge(citing_work_id, work_id)\n",
    "                \n",
    "                # Recursively build the graph\n",
    "                build_citation_graph(citing_work_data, graph, depth + 1, max_depth)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669d3d32-86ac-470b-a62d-ac1a32e71a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doi = '10.1038/nphys1170'\n",
    "#doi = '10.1017/CBO9781107415324'\n",
    "doi = '10.1167/10.3.4' # mine psych\n",
    "#doi = '10.17638/datacat.liverpool.ac.uk/1311' # Liverpool 1\n",
    "#doi = '10.1016/j.heliyon.2024.e30685' # Liverpool 2\n",
    "\n",
    "# Elsevier\n",
    "#doi = '10.7488/ds/1369'  # Edinburgh\n",
    "#doi = '10.17864/1947.256' # Reading\n",
    "#doi = '10.15131/shef.data.11567910' # Sheffield\n",
    "#doi = '10.5523/bris.2fahpksont1zi26xosyamqo8rr' # Bristol\n",
    "\n",
    "# Fetch root work data\n",
    "root_work_data = get_openalex_data(doi)\n",
    "print(root_work_data['title'])\n",
    "print(root_work_data['cited_by_count'])\n",
    "\n",
    "display(JSON(root_work_data))\n",
    "\n",
    "if root_work_data:\n",
    "    # Build the citation graph\n",
    "    citation_graph = build_citation_graph(root_work_data, max_depth=2)\n",
    "\n",
    "    # Create a PyVis network for Jupyter notebook\n",
    "    net = Network(\n",
    "        height='750px',\n",
    "        width='100%',\n",
    "        directed=True,\n",
    "        notebook=True,\n",
    "        cdn_resources='in_line'\n",
    "    )\n",
    "\n",
    "\n",
    "    # Populate the network with the NetworkX graph\n",
    "    net.from_nx(citation_graph)\n",
    "\n",
    "    # Extract all unique concepts and map them to positions on a continuous colormap\n",
    "    concepts = sorted(set(data['primary_concept'] for _, data in citation_graph.nodes(data=True)))\n",
    "    fields = sorted(set(data['field'] for _, data in citation_graph.nodes(data=True)))\n",
    "    cmap = plt.get_cmap('rainbow')\n",
    "    \n",
    "    # Assign each concept a unique color based on its position in the list\n",
    "    concept_colors = {concept: mcolors.rgb2hex(cmap(i / len(concepts))) for i, concept in enumerate(concepts)}\n",
    "    field_colors = {field: mcolors.rgb2hex(cmap(i / len(fields))) for i, field in enumerate(fields)}\n",
    "\n",
    "    # Get the depths of all nodes\n",
    "    depths = [data['depth'] for _, data in citation_graph.nodes(data=True)]\n",
    "    min_depth = min(depths)\n",
    "    max_depth = max(depths)\n",
    "    \n",
    "    # Assign colors based on concept and update node tooltips\n",
    "    for node_id, node_data in citation_graph.nodes(data=True):\n",
    "        field = node_data.get('field', 'Unknown field')\n",
    "        color = field_colors[field]  # Get color for concept\n",
    "        net.get_node(node_id)['color'] = color\n",
    "\n",
    "        depth = node_data['depth']\n",
    "        \n",
    "        # Set node color and tooltip with concept\n",
    "        net.get_node(node_id)['color'] = color\n",
    "        node_doi = node_data.get('doi', 'No DOI')\n",
    "        title = node_data.get('display_name', 'No Title')\n",
    "        publication_year = node_data.get('publication_year', 'Unknown Year')\n",
    "        keywords = node_data.get('keywords', [])\n",
    "        keywords_text = ', '.join([keyword['display_name'] for keyword in keywords]) if keywords else 'No keywords'\n",
    "        net.get_node(node_id)['title'] = f\"{title} ({publication_year})\\nField: {field}\\nKeywords: {keywords_text}\\nDOI: {node_doi}\"\n",
    "        net.get_node(node_id)['label'] = field #title\n",
    "        net.get_node(node_id)['size'] = 100 / (depth+1)  # Adjust size as needed\n",
    "\n",
    "    # Enable physics menu\n",
    "    net.show_buttons()  #filter_=['physics'])\n",
    "\n",
    "    # Generate the HTML content\n",
    "    html_content = net.generate_html()\n",
    "\n",
    "    # Display the network in the notebook\n",
    "    display(HTML(html_content))\n",
    "\n",
    "else:\n",
    "    print('Failed to retrieve root work data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90d6a95-8efb-4059-abf8-e5ae150ba223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19435fb3-882e-470c-bde8-4b5ba5ae6bab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
